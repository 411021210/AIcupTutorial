{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5077d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Softmax, BatchNormalization, Dropout, Add\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d54d124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666d92a",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "Open **dan_train.csv** file and split the games into a list.\n",
    "Every row of csv: `PSL0000000001,1,B[pd],W[dp],B[qp],W[dc],B[nq],W[nc],B[qf],W[kd],B[ce],W[dg],B[dd],W[cc],B[fd],W[ed],B[ee],W[ec],B[ge],W[gc],B[di]`. \n",
    "\n",
    "Columns are:\n",
    "\n",
    "    1. PSL0000000001: Game ID\n",
    "    2. 1: Game Style\n",
    "    3-... : Moves representing this game style\n",
    "    \n",
    "We cropped only the moves to game list as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b559ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('./CSVs/Tutorial_play_style_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "game_styles = [int(i.split(',',2)[-2]) for i in df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f64af3",
   "metadata": {},
   "source": [
    "Create a dictionary to convert the coordinates from characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b52349a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18,\n",
       " 't': 19}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrst'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3429687",
   "metadata": {},
   "source": [
    "We decided to build a DCNN model in this tutorial. We create data samples by using every move in every game, meaning that the target is to predict the next move by feeding the previous state of the table in every game for every move. Therefore, we can collect much more data samples from games.\n",
    "\n",
    "For the simplicity, we used 2 dimensional feature map to represent the data as below:\n",
    " 1. Occupied areas: mark them as 1 and the empty places as 0\n",
    " 2. The last move in the table: mark the position of the last move as 1 and the rest as 0\n",
    " \n",
    "The target is to predict the game style (1, 2 or 3) from the state of the game table. Later this will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b28ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves):\n",
    "    x = np.zeros((19,19,2))\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        x[row,column,0] = 1\n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[row,column,1] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a544a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 10684\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "print(f\"Total Games: {n_games}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30773a",
   "metadata": {},
   "source": [
    "Since play style training has smaller dataset comparing to kyu or dan training, we can put the complete dataset to memory. Still, it is better to create a data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40cce4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for game in games:\n",
    "    moves_list = game.split(',')\n",
    "    x.append(prepare_input(moves_list))\n",
    "x = np.array(x)\n",
    "y = np.array(game_styles)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74d9b37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10684, 19, 19, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad8b3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10684,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f20561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3259, 3796, 3629], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c86e70",
   "metadata": {},
   "source": [
    "Target is one-hot encoded and loss is changed to `categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f30621",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hot = tf.one_hot(y, depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae1a16",
   "metadata": {},
   "source": [
    "Dataset splitting: 90% Training, 10% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80a8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y_hot.numpy(), test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8964d8",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### Simple DCNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6d4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(19, 19, 2))\n",
    "    outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(inputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=1, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Flatten()(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dense(3, activation='softmax', )(outputs)\n",
    "    model = Model(inputs, outputs)\n",
    "    opt = Adam(learning_rate=0.00005)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "295280dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 19, 19, 2)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 19, 19, 32)        3168      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 19, 19, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 19, 19, 32)        50208     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 19, 19, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 19, 19, 32)        25632     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 19, 19, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 19, 19, 32)        25632     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 19, 19, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 19, 19, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 19, 19, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 19, 19, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 19, 19, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 19, 19, 1)         289       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 19, 19, 1)        4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 361)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                11584     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,192\n",
      "Trainable params: 136,678\n",
      "Non-trainable params: 514\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2eaef95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "151/151 [==============================] - 4s 15ms/step - loss: 1.4686 - accuracy: 0.3436 - val_loss: 1.1592 - val_accuracy: 0.3283\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 1.1535 - accuracy: 0.4444 - val_loss: 1.2009 - val_accuracy: 0.3489\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.9786 - accuracy: 0.5392 - val_loss: 1.2401 - val_accuracy: 0.3564\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.8651 - accuracy: 0.6032 - val_loss: 1.2429 - val_accuracy: 0.3779\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.7772 - accuracy: 0.6640 - val_loss: 1.2135 - val_accuracy: 0.4079\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.7007 - accuracy: 0.7152 - val_loss: 1.2239 - val_accuracy: 0.4097\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.6358 - accuracy: 0.7645 - val_loss: 1.2270 - val_accuracy: 0.4060\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.5804 - accuracy: 0.7979 - val_loss: 1.2257 - val_accuracy: 0.4341\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.5380 - accuracy: 0.8256 - val_loss: 1.2226 - val_accuracy: 0.4387\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.4825 - accuracy: 0.8571 - val_loss: 1.2242 - val_accuracy: 0.4518\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.4446 - accuracy: 0.8762 - val_loss: 1.2378 - val_accuracy: 0.4322\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.4026 - accuracy: 0.9009 - val_loss: 1.2458 - val_accuracy: 0.4387\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.3686 - accuracy: 0.9140 - val_loss: 1.2613 - val_accuracy: 0.4415\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.3346 - accuracy: 0.9295 - val_loss: 1.2680 - val_accuracy: 0.4425\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.3075 - accuracy: 0.9425 - val_loss: 1.2774 - val_accuracy: 0.4425\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.2785 - accuracy: 0.9498 - val_loss: 1.2967 - val_accuracy: 0.4490\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.2531 - accuracy: 0.9581 - val_loss: 1.3060 - val_accuracy: 0.4659\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.2361 - accuracy: 0.9606 - val_loss: 1.3197 - val_accuracy: 0.4640\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.2160 - accuracy: 0.9685 - val_loss: 1.3416 - val_accuracy: 0.4780\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.2013 - accuracy: 0.9693 - val_loss: 1.3794 - val_accuracy: 0.4677\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = x_train, \n",
    "    y = y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 20,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed0f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_playstyle.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496855bf",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "**PublicUpload.csv** must be in the following form:\n",
    "```\n",
    "PSTPU0000000001_79,1\n",
    "PSTPU0000000001_7,1\n",
    "PSTPU0000000001_153,1\n",
    "PSTPU0000000001_115,1\n",
    "PSTPU0000000001_131,1\n",
    "PSTPU0000000001_99,1\n",
    "PSTPU0000000001_21,2\n",
    "```\n",
    "\n",
    "- Column 1: Game ID\n",
    "- Column 2: Predicted Game Style\n",
    "\n",
    "The code block below is to use **play_style_test_public.csv** to predict and save the results in required form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56c11247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "df = open('./CSVs/Tutorial_play_style_test_public.csv').read().splitlines()\n",
    "games_id = [i.split(',',2)[0] for i in df]\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "\n",
    "chars = 'abcdefghijklmnopqrst'\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}\n",
    "\n",
    "x_testing = []\n",
    "\n",
    "for game in games:\n",
    "    moves_list = game.split(',')\n",
    "    x_testing.append(prepare_input(moves_list))\n",
    "\n",
    "x_testing = np.array(x_testing)\n",
    "predictions = model.predict(x_testing)\n",
    "prediction_numbers = np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfae7078",
   "metadata": {},
   "source": [
    "Save results to **PublicUpload.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7053c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./PublicUpload.csv','a') as f:\n",
    "    for index, number in enumerate(prediction_numbers):\n",
    "        answer_row = games_id[index] + ',' + str(number+1) + '\\n'\n",
    "        f.write(answer_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436139c",
   "metadata": {},
   "source": [
    "# End of Tutorial\n",
    "\n",
    "You are free to use more modern NN architectures, a better pre-processing, feature extraction methods to achieve much better accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41e067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
